{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15236277",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a97786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee558b",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e8317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/nikhil/Desktop/Machine Learning/ML Datatalks ZoomCamp/Week - 9/train'\n",
    "train_folder = path + '/train'\n",
    "val_folder = path + '/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e53501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['cat.{}.jpg'.format(i) for i in range(10000)]\n",
    "for fname in fnames:\n",
    "    src = path+'/'+fname\n",
    "    dst = train_folder+'/cats/'+fname\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72ef63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['dog.{}.jpg'.format(i) for i in range(10000)]\n",
    "for fname in fnames:\n",
    "    src = path+'/'+fname\n",
    "    dst = train_folder+'/dogs/'+fname\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6223aa4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/nikhil/Desktop/Machine Learning/ML Datatalks ZoomCamp/Week - 9/train/cat.12500.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-db8375ec63be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_folder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/cats/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;31m# macOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/nikhil/Desktop/Machine Learning/ML Datatalks ZoomCamp/Week - 9/train/cat.12500.jpg'"
     ]
    }
   ],
   "source": [
    "fnames = ['cat.{}.jpg'.format(i) for i in range(10000, 12500)]\n",
    "for fname in fnames:\n",
    "    src = path+'/'+fname\n",
    "    dst = val_folder+'/cats/'+fname\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9adfe56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['dog.{}.jpg'.format(i) for i in range(10000, 12500)]\n",
    "for fname in fnames:\n",
    "    src = path+'/'+fname\n",
    "    dst = val_folder+'/dogs/'+fname\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79bfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50373606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are :  10000  for Category ->  cats  in folder :  train\n",
      "There are :  10000  for Category ->  dogs  in folder :  train\n",
      "There are :  2500  for Category ->  cats  in folder :  val\n",
      "There are :  2500  for Category ->  dogs  in folder :  val\n"
     ]
    }
   ],
   "source": [
    "for data in ['train', 'val']:\n",
    "    for c in ['cats', 'dogs']:\n",
    "        total_images = len(os.listdir(path+'/'+data+'/'+c))\n",
    "        print(\"There are : \", total_images, \" for Category -> \", c, \" in folder : \", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a253cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers= [\n",
    "    # The shape for input should be (150, 150, 3)\n",
    "    keras.Input(shape=(150,150,3), name ='input'),\n",
    "    # Next, create a covolutional layer (Conv2D)\n",
    "    # Use 32 filters\n",
    "    # Kernel size should be (3, 3) (that's the size of the filter)\n",
    "    # Use 'relu' as activation\n",
    "    keras.layers.Conv2D(\n",
    "        filters = 32, \n",
    "        kernel_size = (3,3),\n",
    "        name = 'Conv-Layer',\n",
    "        activation = 'relu'\n",
    "    ),\n",
    "    # Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "    # Set the pooling size to (2, 2)\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), name = 'MaxPooling'),\n",
    "    # Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "    keras.layers.Flatten(name = 'Flatten'),\n",
    "    # Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "    keras.layers.Dense(units = 64, activation='relu', name='inner_dense'),\n",
    "    # Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "    # The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "    keras.layers.Dense(units = 1, activation='sigmoid', name='output')\n",
    "    \n",
    "]\n",
    "\n",
    "# compiling the layers in model\n",
    "model = Sequential(Layers)\n",
    "\n",
    "# As optimizer use SGD with the following parameters:\n",
    "# SGD(lr=0.002, momentum=0.8)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate = 0.002, momentum = 0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a81df",
   "metadata": {},
   "source": [
    "# Question 1:\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "Note: since we specify an activation for the output layer, we don't need to set from_logits=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5650e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = optimizer,\n",
    "             metrics = ['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca3025",
   "metadata": {},
   "source": [
    "# Answer 1 : Best Loss Function : binary cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ec991",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "What's the total number of parameters of the model? You can use the summary method for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80320f0a",
   "metadata": {},
   "source": [
    "# Generators and Training\n",
    "\n",
    "For the next two questions, use the following data generator for both train and validation:\n",
    "\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "We don't need to do any additional pre-processing for the images.\n",
    "When reading the data from train/val directories, check the class_mode parameter. \n",
    "\n",
    "Which value should it be for a binary classification problem?\n",
    "Use batch_size=20\n",
    "\n",
    "For training use .fit() with the following params:\n",
    "\n",
    "\n",
    "model.fit(\n",
    "\n",
    "    train_generator,\n",
    "    \n",
    "    steps_per_epoch=100,\n",
    "    \n",
    "    epochs=10,\n",
    "    \n",
    "    validation_data=validation_generator,\n",
    "    \n",
    "    validation_steps=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c501ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv-Layer (Conv2D)          (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "MaxPooling (MaxPooling2D)    (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 175232)            0         \n",
      "_________________________________________________________________\n",
      "inner_dense (Dense)          (None, 64)                11214912  \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c56bc",
   "metadata": {},
   "source": [
    "# Answer 2 : 11,215,873"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ae6113",
   "metadata": {},
   "source": [
    "# Question 3 \n",
    "\n",
    "What is the median of training accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c560bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "train_ds = train_gen.flow_from_directory(train_folder,\n",
    "                                         target_size=(150, 150),\n",
    "                                         class_mode='binary',\n",
    "                                         batch_size=20) \n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "val_ds = val_gen.flow_from_directory(val_folder,\n",
    "                                    target_size = (150,150),\n",
    "                                    class_mode = 'binary',\n",
    "                                    batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eedbe586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 62s 606ms/step - loss: 0.6996 - accuracy: 0.5185 - val_loss: 0.6910 - val_accuracy: 0.5090\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 0.6840 - accuracy: 0.5465 - val_loss: 0.6848 - val_accuracy: 0.5570\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 52s 518ms/step - loss: 0.6797 - accuracy: 0.5615 - val_loss: 0.6734 - val_accuracy: 0.5820\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 50s 504ms/step - loss: 0.6698 - accuracy: 0.5780 - val_loss: 0.6729 - val_accuracy: 0.5800\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 44s 441ms/step - loss: 0.6604 - accuracy: 0.5980 - val_loss: 0.6897 - val_accuracy: 0.5320\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 43s 426ms/step - loss: 0.6559 - accuracy: 0.6080 - val_loss: 0.6610 - val_accuracy: 0.5960\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 42s 417ms/step - loss: 0.6485 - accuracy: 0.6085 - val_loss: 0.6548 - val_accuracy: 0.6220\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 40s 401ms/step - loss: 0.6360 - accuracy: 0.6420 - val_loss: 0.6429 - val_accuracy: 0.6140\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 38s 383ms/step - loss: 0.6389 - accuracy: 0.6305 - val_loss: 0.6356 - val_accuracy: 0.6230\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 0.6424 - accuracy: 0.6200 - val_loss: 0.6339 - val_accuracy: 0.6330\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t_model = model.fit(train_ds,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c809413b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.699600100517273,\n",
       "  0.6839891672134399,\n",
       "  0.6797141432762146,\n",
       "  0.6698445081710815,\n",
       "  0.6603745818138123,\n",
       "  0.6559429168701172,\n",
       "  0.6484664082527161,\n",
       "  0.6359925270080566,\n",
       "  0.6388604640960693,\n",
       "  0.6424087882041931],\n",
       " 'accuracy': [0.5184999704360962,\n",
       "  0.546500027179718,\n",
       "  0.5615000128746033,\n",
       "  0.578000009059906,\n",
       "  0.5979999899864197,\n",
       "  0.6079999804496765,\n",
       "  0.6085000038146973,\n",
       "  0.6420000195503235,\n",
       "  0.6305000185966492,\n",
       "  0.6200000047683716],\n",
       " 'val_loss': [0.6909972429275513,\n",
       "  0.6847776174545288,\n",
       "  0.673385500907898,\n",
       "  0.6728634834289551,\n",
       "  0.6897282004356384,\n",
       "  0.6609770655632019,\n",
       "  0.6547914147377014,\n",
       "  0.6428967714309692,\n",
       "  0.6355530619621277,\n",
       "  0.6339273452758789],\n",
       " 'val_accuracy': [0.5090000033378601,\n",
       "  0.5569999814033508,\n",
       "  0.5820000171661377,\n",
       "  0.5799999833106995,\n",
       "  0.5320000052452087,\n",
       "  0.5960000157356262,\n",
       "  0.621999979019165,\n",
       "  0.6140000224113464,\n",
       "  0.6230000257492065,\n",
       "  0.6330000162124634]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c27261e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_training_accuracy :  0.59\n"
     ]
    }
   ],
   "source": [
    "median_training_accuracy = np.mean(t_model.history['accuracy'])\n",
    "print(\"median_training_accuracy : \", median_training_accuracy.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6091a745",
   "metadata": {},
   "source": [
    "# Answer 3 : 0.56"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7533336",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "What is the standard deviation of training loss for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "116303ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_dev_training_loss :  0.0202\n"
     ]
    }
   ],
   "source": [
    "std_dev_training_loss = np.std(t_model.history['loss'])\n",
    "print(\"std_dev_training_loss : \", std_dev_training_loss.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc85b3",
   "metadata": {},
   "source": [
    "# Answer 4 : 0.01 (closest approximation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae29d0e3",
   "metadata": {},
   "source": [
    " # Data Augmentation\n",
    "For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46e3c1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255,\n",
    "                               rotation_range=40,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True,\n",
    "                               fill_mode='nearest')\n",
    "train_ds = train_gen.flow_from_directory(train_folder,\n",
    "                                        target_size = (150,150),\n",
    "                                        class_mode = 'binary',\n",
    "                                        batch_size = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef0d6b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 58s 580ms/step - loss: 0.6392 - accuracy: 0.6270 - val_loss: 0.6062 - val_accuracy: 0.6650\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 0.6367 - accuracy: 0.6295 - val_loss: 0.7034 - val_accuracy: 0.5840\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 52s 516ms/step - loss: 0.6316 - accuracy: 0.6450 - val_loss: 0.6028 - val_accuracy: 0.6720\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.6335 - accuracy: 0.6425 - val_loss: 0.5946 - val_accuracy: 0.7020\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 53s 527ms/step - loss: 0.6327 - accuracy: 0.6515 - val_loss: 0.5938 - val_accuracy: 0.6960\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.6263 - accuracy: 0.6525 - val_loss: 0.5974 - val_accuracy: 0.6840\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 53s 531ms/step - loss: 0.6302 - accuracy: 0.6310 - val_loss: 0.5857 - val_accuracy: 0.7090\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 53s 527ms/step - loss: 0.6313 - accuracy: 0.6425 - val_loss: 0.6033 - val_accuracy: 0.6730\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.6377 - accuracy: 0.6325 - val_loss: 0.6032 - val_accuracy: 0.6730\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 0.6251 - accuracy: 0.6360 - val_loss: 0.6122 - val_accuracy: 0.6580\n"
     ]
    }
   ],
   "source": [
    "# Let's train our model for 10 more epochs using the same code as previously. \n",
    "# Make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "\n",
    "\n",
    "t_model = model.fit(train_ds,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17504780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6391681432723999,\n",
       "  0.636695921421051,\n",
       "  0.6315542459487915,\n",
       "  0.6334671974182129,\n",
       "  0.632651150226593,\n",
       "  0.6263101100921631,\n",
       "  0.6301519870758057,\n",
       "  0.6313118934631348,\n",
       "  0.6376796364784241,\n",
       "  0.6250604391098022],\n",
       " 'accuracy': [0.6269999742507935,\n",
       "  0.6294999718666077,\n",
       "  0.6449999809265137,\n",
       "  0.6424999833106995,\n",
       "  0.6514999866485596,\n",
       "  0.6524999737739563,\n",
       "  0.6309999823570251,\n",
       "  0.6424999833106995,\n",
       "  0.6324999928474426,\n",
       "  0.6359999775886536],\n",
       " 'val_loss': [0.6062123775482178,\n",
       "  0.7034369111061096,\n",
       "  0.6027674674987793,\n",
       "  0.5945980548858643,\n",
       "  0.5938239097595215,\n",
       "  0.5974228978157043,\n",
       "  0.585679829120636,\n",
       "  0.6033152937889099,\n",
       "  0.603245198726654,\n",
       "  0.612169623374939],\n",
       " 'val_accuracy': [0.6650000214576721,\n",
       "  0.5839999914169312,\n",
       "  0.671999990940094,\n",
       "  0.7020000219345093,\n",
       "  0.6959999799728394,\n",
       "  0.6840000152587891,\n",
       "  0.7089999914169312,\n",
       "  0.6729999780654907,\n",
       "  0.6729999780654907,\n",
       "  0.6579999923706055]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_model.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b7e8f",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "What is the mean of validation loss for the model trained with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f71d12e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_validation_loss :  0.6102671563625336\n"
     ]
    }
   ],
   "source": [
    "mean_validation_loss = np.mean(t_model.history['val_loss'])\n",
    "print(\"mean_validation_loss : \", mean_validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8404dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61\n"
     ]
    }
   ],
   "source": [
    "print(mean_validation_loss.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd59e36",
   "metadata": {},
   "source": [
    "# Answer 5 : 0.67 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48700b5a",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "What's the average of validation accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca257d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6840000152587891,\n",
       " 0.7089999914169312,\n",
       " 0.6729999780654907,\n",
       " 0.6729999780654907,\n",
       " 0.6579999923706055]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_model.history['val_accuracy'][5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e731b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_validation_accuracy :  0.6793999910354614\n"
     ]
    }
   ],
   "source": [
    "mean_validation_accuracy = np.mean(t_model.history['val_accuracy'][5:10])\n",
    "print(\"mean_validation_accuracy : \", mean_validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbdad9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.679\n"
     ]
    }
   ],
   "source": [
    "print(mean_validation_accuracy.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed90afa",
   "metadata": {},
   "source": [
    "# Answer 6 :  0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02676a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
